# -*- coding: utf-8 -*-
"""Random Forest Methodology for Analyzing Diabetes Risk Factors

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AnTxi52igBplNY6d2GykmJgXZ9aj1hLU
"""

# Import necessary libraries
import pandas as pd
from google.colab import files

# Session 1: Upload the dataset
uploaded = files.upload()

# Load the dataset (assuming it's a CSV file)
file_name = list(uploaded.keys())[0]  # Get the uploaded file name
data = pd.read_csv(file_name)

# Show the first few rows to verify that it's loaded correctly
data.head()

# Session 2: Data processing and model results for analyzing diabetes risk factors

# Importing necessary libraries for model training and evaluation
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns
import time

# Prepare the features (X) and target variable (y)
X = data.drop("Outcome", axis=1)
y = data["Outcome"]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Standardize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialize and train the model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Model Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Model accuracy: {accuracy * 100:.2f}%")

# Classification report
print("Classification Report for Diabetes Risk Prediction:")
print(classification_report(y_test, y_pred))

# Confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix (True Positive, False Positive, True Negative, False Negative):")
print(conf_matrix)

# Plot confusion matrix
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Diabetes Risk Prediction')
plt.show()

# Feature Importance (Analyzing Risk Factors for Diabetes)
feature_importances = model.feature_importances_
features = X.columns
plt.barh(features, feature_importances)
plt.xlabel('Importance')
plt.title('Feature Importance: Analyzing Diabetes Risk Factors')
plt.show()

# Feature analysis: which features contribute most to predicting diabetes risk?
print("Most important features contributing to diabetes risk prediction:")
sorted_idx = np.argsort(feature_importances)[::-1]
for idx in sorted_idx:
    print(f"{features[idx]}: Importance - {feature_importances[idx]:.4f}")

# Model Processing Time
start_time = time.time()
# Simulating model processing time
end_time = time.time()
print(f"Model Processing Time: {end_time - start_time:.2f} seconds")